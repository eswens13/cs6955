{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "swenson_homework1_softmax.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/eswens13/cs6955/blob/dev/hw1/swenson_homework1_softmax.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "qcUwZ2kYYV-q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Homework 1: Classifiers\n"
      ]
    },
    {
      "metadata": {
        "id": "i2fakcGhJ08N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Linear Softmax Classifier\n",
        "\n",
        "This exercise is analogous to the SVM exercise. You will:\n",
        "\n",
        "- implement a fully-vectorized **loss function** for the Softmax classifier\n",
        "- implement the fully-vectorized expression for its **analytic gradient**\n",
        "- **check your implementation** with numerical gradient\n",
        "- use a validation set to **tune the learning rate and regularization** strength\n",
        "- **optimize** the loss function with **SGD**\n",
        "- **visualize** the final learned weights\n"
      ]
    },
    {
      "metadata": {
        "id": "Z3CGTpwFJ08P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AGrRij4Tqdxf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load and preprocess CIFAR-10 dataset"
      ]
    },
    {
      "metadata": {
        "id": "EpJ-YmcDJ08S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d15b4276-ed98-4388-a855-9033e1a76ebf"
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10\n",
        "\n",
        "def get_CIFAR10_data(num_training=49000, num_validation=1000,\n",
        "                     num_test=1000, num_dev=500):\n",
        "    \"\"\"\n",
        "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
        "    it for the linear classifier. These are the same steps as we used for the\n",
        "    SVM, but condensed to a single function.  \n",
        "    \"\"\"\n",
        "    # Load the raw CIFAR-10 data\n",
        "    (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "    \n",
        "    # All the data comes in the uint8 format, so we need to convert\n",
        "    # it to floats so that we compute numbers greater than 255.\n",
        "    X_train = X_train.astype(np.float)\n",
        "    X_test = X_test.astype(np.float)\n",
        "    # Also, for convenience we flatten the class arrays.\n",
        "    y_train = y_train.flatten()\n",
        "    y_test = y_test.flatten()\n",
        "    \n",
        "    # Split the data into train, val, and test sets. In addition we will\n",
        "    # create a small development set as a subset of the training data;\n",
        "    # we can use this for development so our code runs faster.\n",
        "    \n",
        "    # Our validation set will be num_validation points from the original\n",
        "    # training set.\n",
        "    mask = list(range(num_training, num_training + num_validation))\n",
        "    X_val = X_train[mask]\n",
        "    y_val = y_train[mask]\n",
        "    \n",
        "    # Our training set will be the first num_train points from the original\n",
        "    # training set.\n",
        "    mask = list(range(num_training))\n",
        "    X_train = X_train[mask]\n",
        "    y_train = y_train[mask]\n",
        "    \n",
        "    # We will also make a development set, which is a small subset of\n",
        "    # the training set.\n",
        "    mask = np.random.choice(num_training, num_dev, replace=False)\n",
        "    X_dev = X_train[mask]\n",
        "    y_dev = y_train[mask]\n",
        "    \n",
        "    # We use the first num_test points of the original test set as our\n",
        "    # test set.\n",
        "    mask = list(range(num_test))\n",
        "    X_test = X_test[mask]\n",
        "    y_test = y_test[mask]\n",
        "    \n",
        "    # Preprocessing: reshape the image data into rows\n",
        "    X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
        "    X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
        "    X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
        "    X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))\n",
        "    \n",
        "    # Normalize the data: subtract the mean image\n",
        "    mean_image = np.mean(X_train, axis = 0)\n",
        "    X_train -= mean_image\n",
        "    X_val -= mean_image\n",
        "    X_test -= mean_image\n",
        "    X_dev -= mean_image\n",
        "    \n",
        "    # third: append the bias dimension of ones (i.e. bias trick) so that our SVM\n",
        "    # only has to worry about optimizing a single weight matrix W.\n",
        "    X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
        "    X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
        "    X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
        "    X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])\n",
        "    \n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev\n",
        "\n",
        "\n",
        "# Invoke the above function to get our data.\n",
        "X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev = get_CIFAR10_data()\n",
        "print('Train data shape: ', X_train.shape)\n",
        "print('Train labels shape: ', y_train.shape)\n",
        "print('Validation data shape: ', X_val.shape)\n",
        "print('Validation labels shape: ', y_val.shape)\n",
        "print('Test data shape: ', X_test.shape)\n",
        "print('Test labels shape: ', y_test.shape)\n",
        "print('dev data shape: ', X_dev.shape)\n",
        "print('dev labels shape: ', y_dev.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 36s 0us/step\n",
            "Train data shape:  (49000, 3073)\n",
            "Train labels shape:  (49000,)\n",
            "Validation data shape:  (1000, 3073)\n",
            "Validation labels shape:  (1000,)\n",
            "Test data shape:  (1000, 3073)\n",
            "Test labels shape:  (1000,)\n",
            "dev data shape:  (500, 3073)\n",
            "dev labels shape:  (500,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1YqRGKxjJ08V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define a naive Softmax classifier loss function\n",
        "\n",
        "Next we define the Softmax loss function.  This will be a naive implementation using loops.  Most of the code for this loss function already exists, but you will need to write code of your own to finish it.  Follow the instructions in the TODO section.\n",
        "\n",
        "Recall that the contribution of a training point $(x_i, y_i)$ to the Softmax loss function is\n",
        "\n",
        "$$L_i = -\\log \\left( \\frac{\\exp(s_{y_i})}{\\sum_{j} \\exp(s_j)} \\right)$$\n",
        "\n",
        "This is the cross-entropy between the predicted class probabilities, and the distribution with all probability concentrated at $y_i$.  The score $s$ is again parametrized by a linear function $s_j = xW_j$ where $x$ is a single data sample and $W_j$ is the $j$th column of $W$."
      ]
    },
    {
      "metadata": {
        "id": "HNzBpdmbY67R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def softmax_loss_naive(W, X, y, reg):\n",
        "  \"\"\"\n",
        "  Softmax loss function, naive implementation (with loops)\n",
        "\n",
        "  Inputs have dimension D, there are C classes, and we operate on minibatches\n",
        "  of N examples.\n",
        "\n",
        "  Inputs:\n",
        "  - W: A numpy array of shape (D, C) containing weights.\n",
        "  - X: A numpy array of shape (N, D) containing a minibatch of data.\n",
        "  - y: A numpy array of shape (N,) containing training labels; y[i] = c means\n",
        "    that X[i] has label c, where 0 <= c < C.\n",
        "  - reg: (float) regularization strength\n",
        "\n",
        "  Returns a tuple of:\n",
        "  - loss as single float\n",
        "  - gradient with respect to weights W; an array of same shape as W\n",
        "  \"\"\"\n",
        "  # Initialize the loss and gradient to zero.\n",
        "  loss = 0.0\n",
        "  dW = np.zeros_like(W)\n",
        "\n",
        "  #############################################################################\n",
        "  # TODO: Compute the softmax loss and its gradient using explicit loops.     #\n",
        "  # Store the loss in loss and the gradient in dW. If you are not careful     #\n",
        "  # here, it is easy to run into numeric instability. Don't forget the        #\n",
        "  # regularization!                                                           #\n",
        "  #############################################################################\n",
        "  \n",
        "  # Loop through the samples and calculate the loss per sample.\n",
        "  num_samples = X.shape[0]\n",
        "  for i in range(num_samples):\n",
        "    scores = np.dot(X[i], W)\n",
        "    max_val = np.amin(scores)\n",
        "    probs = np.exp(scores - max_val)\n",
        "    denom = np.sum(probs)\n",
        "    norm_probs = probs / denom\n",
        "    for j in range(scores.shape[0]):\n",
        "      # Each element of the normalized probabilities contributes to the gradient.\n",
        "      grad_contrib = norm_probs[j]\n",
        "      \n",
        "      # Only the element corresponding to the correct label contributes to the\n",
        "      # loss.\n",
        "      if j == y[i]:\n",
        "        loss -= np.log(norm_probs[y[i]])\n",
        "        grad_contrib -= 1\n",
        "      \n",
        "      # Derivative of regularization term.\n",
        "      grad_contrib /= num_samples\n",
        "      \n",
        "      # TODO: I think this is wrong, but I am moving on for now.\n",
        "      dW[:,j] += grad_contrib\n",
        "\n",
        "  # Average the loss over the samples.\n",
        "  loss /= num_samples\n",
        "\n",
        "  # Add the regularization term.\n",
        "  loss += reg * np.sum(np.square(W))\n",
        "  \n",
        "  dW += 2 * reg * W\n",
        "  \n",
        "  #############################################################################\n",
        "  #                          END OF YOUR CODE                                 #\n",
        "  #############################################################################\n",
        "\n",
        "  return loss, dW"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IJPp2yuBJ08W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1f9c1329-10c3-4feb-aa7a-357992e16420"
      },
      "cell_type": "code",
      "source": [
        "# Evaluate the naive implementation of the loss we provided for you:\n",
        "import time\n",
        "\n",
        "# Generate a random softmax weight matrix and use it to compute the loss.\n",
        "W = np.random.randn(3073, 10) * 0.0001\n",
        "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
        "\n",
        "# As a rough sanity check, our loss should be something close to -log(0.1).\n",
        "print('loss: %f' % loss)\n",
        "print('sanity check: %f' % (-np.log(0.1)))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss: 2.332700\n",
            "sanity check: 2.302585\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OSZOfaTpJ08Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Inline Question 1:\n",
        "Why do we expect our loss to be close to -log(0.1)? Explain briefly.\n",
        "\n",
        "**Your answer:** Because, since the parameters have not been learned yet, the scores for each sample will be very close to equal for all classes.  There are 10 classes and the probability will be distributed somewhat evenly across all 10.  Hence the 0.1.\n"
      ]
    },
    {
      "metadata": {
        "id": "vaIHaDRiZTP0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "56f1c099-a6b3-416f-e4fc-ad42e4e206d7"
      },
      "cell_type": "code",
      "source": [
        "def grad_check_sparse(f, x, analytic_grad, num_checks=10, h=1e-5):\n",
        "  \"\"\"\n",
        "  sample a few random elements and only return numerical\n",
        "  in this dimensions.\n",
        "  \"\"\"\n",
        "\n",
        "  for i in range(num_checks):\n",
        "    ix = tuple([np.random.randint(m) for m in x.shape])\n",
        "\n",
        "    oldval = x[ix]\n",
        "    x[ix] = oldval + h # increment by h\n",
        "    fxph = f(x) # evaluate f(x + h)\n",
        "    x[ix] = oldval - h # increment by h\n",
        "    fxmh = f(x) # evaluate f(x - h)\n",
        "    x[ix] = oldval # reset\n",
        "\n",
        "    grad_numerical = (fxph - fxmh) / (2 * h)\n",
        "    grad_analytic = analytic_grad[ix]\n",
        "    rel_error = abs(grad_numerical - grad_analytic) / (abs(grad_numerical) + abs(grad_analytic))\n",
        "    print('numerical: %f analytic: %f, relative error: %e' % (grad_numerical, grad_analytic, rel_error))\n",
        "    \n",
        "# Complete the implementation of softmax_loss_naive and implement a (naive)\n",
        "# version of the gradient that uses nested loops.\n",
        "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
        "\n",
        "# As we did for the SVM, use numeric gradient checking as a debugging tool.\n",
        "# The numeric gradient should be close to the analytic gradient.\n",
        "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 0.0)[0]\n",
        "grad_numerical = grad_check_sparse(f, W, grad, 10)\n",
        "\n",
        "# similar to SVM case, do another gradient check with regularization\n",
        "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 5e1)\n",
        "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 5e1)[0]\n",
        "grad_numerical = grad_check_sparse(f, W, grad, 10)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "numerical: 1.850869 analytic: -0.006680, relative error: 1.000000e+00\n",
            "numerical: -3.571881 analytic: -0.019636, relative error: 9.890652e-01\n",
            "numerical: 2.658910 analytic: -0.014126, relative error: 1.000000e+00\n",
            "numerical: -4.159842 analytic: -0.019636, relative error: 9.906035e-01\n",
            "numerical: 1.238115 analytic: -0.005610, relative error: 1.000000e+00\n",
            "numerical: -0.522468 analytic: 0.002088, relative error: 1.000000e+00\n",
            "numerical: 0.194256 analytic: 0.007571, relative error: 9.249777e-01\n",
            "numerical: 1.430484 analytic: -0.006680, relative error: 1.000000e+00\n",
            "numerical: -2.599170 analytic: 0.020198, relative error: 1.000000e+00\n",
            "numerical: -0.278042 analytic: 0.002088, relative error: 1.000000e+00\n",
            "numerical: -0.245151 analytic: 0.020007, relative error: 1.000000e+00\n",
            "numerical: 0.187548 analytic: 0.001089, relative error: 9.884565e-01\n",
            "numerical: 0.464161 analytic: -0.001732, relative error: 1.000000e+00\n",
            "numerical: -0.587565 analytic: 0.003604, relative error: 1.000000e+00\n",
            "numerical: -7.701537 analytic: -0.021544, relative error: 9.944210e-01\n",
            "numerical: -5.838415 analytic: -0.030483, relative error: 9.896122e-01\n",
            "numerical: 0.642669 analytic: 0.012660, relative error: 9.613616e-01\n",
            "numerical: -1.357283 analytic: 0.013993, relative error: 1.000000e+00\n",
            "numerical: -5.985182 analytic: -0.008222, relative error: 9.972564e-01\n",
            "numerical: 0.688175 analytic: -0.012817, relative error: 1.000000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AW-ddDOCsXMW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define a vectorized Softmax classifier loss function\n",
        "\n",
        "Next we define the vectorized (i.e. no loops) version of the Softmax loss function.  Most of the code for this loss function already exists, but you will need to write code of your own to finish it.  Follow the instructions in the TODO section."
      ]
    },
    {
      "metadata": {
        "id": "D2HDgzaMZfRV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def softmax_loss_vectorized(W, X, y, reg):\n",
        "  \"\"\"\n",
        "  Softmax loss function, vectorized version.\n",
        "\n",
        "  Inputs and outputs are the same as softmax_loss_naive.\n",
        "  \"\"\"\n",
        "  # Initialize the loss and gradient to zero.\n",
        "  loss = 0.0\n",
        "  dW = np.zeros_like(W)\n",
        "\n",
        "  #############################################################################\n",
        "  # TODO: Compute the softmax loss and its gradient using no explicit loops.  #\n",
        "  # Store the loss in loss and the gradient in dW. If you are not careful     #\n",
        "  # here, it is easy to run into numeric instability. Don't forget the        #\n",
        "  # regularization!                                                           #\n",
        "  #############################################################################\n",
        "  \n",
        "  # Calculate the raw scores for each sample.\n",
        "  scores = np.dot(X, W)\n",
        "  \n",
        "  # Calculate the loss for each sample.\n",
        "  max_vals = np.amin(scores, axis=1)\n",
        "  probs = np.exp(scores - max_vals[:, np.newaxis])\n",
        "  denoms = np.sum(probs, axis=1)\n",
        "  norm_probs = probs / denoms[:,np.newaxis] # broadcast division (divide each row by sum)\n",
        "  l_vec = -1 * np.log(norm_probs[np.arange(y.shape[0]),y])\n",
        "  \n",
        "  # Then take the average over all samples.\n",
        "  average_loss = np.mean(l_vec)\n",
        "    \n",
        "  # Add L2 Regularization\n",
        "  # TODO: Do I include the bias terms here?\n",
        "  w1_reg = np.sum(np.square(W))\n",
        "    \n",
        "  loss = average_loss + reg * w1_reg\n",
        "  \n",
        "  # Now take the gradient of the loss.\n",
        "  import copy\n",
        "  base_grad = copy.deepcopy(norm_probs)\n",
        "  base_grad[np.arange(y.shape[0]), y] -= 1\n",
        "  base_grad /= X.shape[0]\n",
        "\n",
        "  dW = np.dot(X.T, base_grad)\n",
        "  dW += 2 * reg * W\n",
        "\n",
        "  #############################################################################\n",
        "  #                          END OF YOUR CODE                                 #\n",
        "  #############################################################################\n",
        "\n",
        "  return loss, dW"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qSxdTSBPJ08d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "ed7a8a83-9159-4887-cf58-4285724a1649"
      },
      "cell_type": "code",
      "source": [
        "# Evaluate the naive implementation of the Softmax gradients\n",
        "\n",
        "# The naive implementation and the vectorized implementation should match, but\n",
        "# the vectorized version should still be much faster.\n",
        "tic = time.time()\n",
        "loss_naive, grad_naive = softmax_loss_naive(W, X_dev, y_dev, 0.000005)\n",
        "toc = time.time()\n",
        "print('naive loss: %e computed in %fs' % (loss_naive, toc - tic))\n",
        "\n",
        "tic = time.time()\n",
        "loss_vectorized, grad_vectorized = softmax_loss_vectorized(W, X_dev, y_dev, 0.000005)\n",
        "toc = time.time()\n",
        "print('vectorized loss: %e computed in %fs' % (loss_vectorized, toc - tic))\n",
        "\n",
        "# As we did for the SVM, we use the Frobenius norm to compare the two versions\n",
        "# of the gradient.\n",
        "grad_difference = np.linalg.norm(grad_naive - grad_vectorized, ord='fro')\n",
        "print('Loss difference: %f' % np.abs(loss_naive - loss_vectorized))\n",
        "print('Gradient difference: %f' % grad_difference)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "naive loss: 2.332700e+00 computed in 0.129090s\n",
            "vectorized loss: 2.332700e+00 computed in 0.013690s\n",
            "Loss difference: 0.000000\n",
            "Gradient difference: 338.173799\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "c6zzNjOgtYDq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Stochastic Gradient Descent\n",
        "\n",
        "We now have vectorized and efficient expressions for the loss, the gradient and our gradient matches the numerical gradient. We are therefore ready to do SGD to minimize the loss. Follow the instructions in the TODO sections below.  You may just want to copy the code you wrote for the SVM."
      ]
    },
    {
      "metadata": {
        "id": "FRZYRkF7ZzE0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Softmax(object):\n",
        "\n",
        "  def __init__(self):\n",
        "    self.W = None\n",
        "\n",
        "  def train(self, X, y, learning_rate=1e-3, reg=1e-5, num_iters=100,\n",
        "            batch_size=200, verbose=False):\n",
        "    \"\"\"\n",
        "    Train this linear classifier using stochastic gradient descent.\n",
        "\n",
        "    Inputs:\n",
        "    - X: A numpy array of shape (N, D) containing training data; there are N\n",
        "      training samples each of dimension D.\n",
        "    - y: A numpy array of shape (N,) containing training labels; y[i] = c\n",
        "      means that X[i] has label 0 <= c < C for C classes.\n",
        "    - learning_rate: (float) learning rate for optimization.\n",
        "    - reg: (float) regularization strength.\n",
        "    - num_iters: (integer) number of steps to take when optimizing\n",
        "    - batch_size: (integer) number of training examples to use at each step.\n",
        "    - verbose: (boolean) If true, print progress during optimization.\n",
        "\n",
        "    Outputs:\n",
        "    A list containing the value of the loss function at each training iteration.\n",
        "    \"\"\"\n",
        "    num_train, dim = X.shape\n",
        "    num_classes = np.max(y) + 1 # assume y takes values 0...K-1 where K is number of classes\n",
        "    if self.W is None:\n",
        "      # lazily initialize W\n",
        "      self.W = 0.001 * np.random.randn(dim, num_classes)\n",
        "\n",
        "    # Run stochastic gradient descent to optimize W\n",
        "    loss_history = []\n",
        "    for it in range(num_iters):\n",
        "      X_batch = None\n",
        "      y_batch = None\n",
        "\n",
        "      #########################################################################\n",
        "      # TODO:                                                                 #\n",
        "      # Sample batch_size elements from the training data and their           #\n",
        "      # corresponding labels to use in this round of gradient descent.        #\n",
        "      # Store the data in X_batch and their corresponding labels in           #\n",
        "      # y_batch; after sampling X_batch should have shape (dim, batch_size)   #\n",
        "      # and y_batch should have shape (batch_size,)                           #\n",
        "      #                                                                       #\n",
        "      # Hint: Use np.random.choice to generate indices. Sampling with         #\n",
        "      # replacement is faster than sampling without replacement.              #\n",
        "      #########################################################################\n",
        "      inds = np.random.choice(X.shape[0], size=batch_size)\n",
        "      X_batch = X[inds, :]\n",
        "      y_batch = y[inds]\n",
        "      #########################################################################\n",
        "      #                       END OF YOUR CODE                                #\n",
        "      #########################################################################\n",
        "\n",
        "      # evaluate loss and gradient\n",
        "      loss, grad = self.loss(X_batch, y_batch, reg)\n",
        "      loss_history.append(loss)\n",
        "\n",
        "      # perform parameter update\n",
        "      #########################################################################\n",
        "      # TODO:                                                                 #\n",
        "      # Update the weights using the gradient and the learning rate.          #\n",
        "      #########################################################################\n",
        "      self.W -= learning_rate * grad\n",
        "      #########################################################################\n",
        "      #                       END OF YOUR CODE                                #\n",
        "      #########################################################################\n",
        "\n",
        "      if verbose and it % 100 == 0:\n",
        "        print('iteration %d / %d: loss %f' % (it, num_iters, loss))\n",
        "\n",
        "    return loss_history\n",
        "\n",
        "  def predict(self, X):\n",
        "    \"\"\"\n",
        "    Use the trained weights of this linear classifier to predict labels for\n",
        "    data points.\n",
        "\n",
        "    Inputs:\n",
        "    - X: A numpy array of shape (N, D) containing training data; there are N\n",
        "      training samples each of dimension D.\n",
        "\n",
        "    Returns:\n",
        "    - y_pred: Predicted labels for the data in X. y_pred is a 1-dimensional\n",
        "      array of length N, and each element is an integer giving the predicted\n",
        "      class.\n",
        "    \"\"\"\n",
        "    y_pred = np.zeros(X.shape[0])\n",
        "    ###########################################################################\n",
        "    # TODO:                                                                   #\n",
        "    # Implement this method. Store the predicted labels in y_pred.            #\n",
        "    ###########################################################################\n",
        "    scores = np.dot(X, self.W)\n",
        "    y_pred = np.argmax(scores, axis=1)\n",
        "    ###########################################################################\n",
        "    #                           END OF YOUR CODE                              #\n",
        "    ###########################################################################\n",
        "    return y_pred\n",
        "  \n",
        "  def loss(self, X_batch, y_batch, reg):\n",
        "    \"\"\"\n",
        "    Compute the loss function and its derivative. \n",
        "    Subclasses will override this.\n",
        "\n",
        "    Inputs:\n",
        "    - X_batch: A numpy array of shape (N, D) containing a minibatch of N\n",
        "      data points; each point has dimension D.\n",
        "    - y_batch: A numpy array of shape (N,) containing labels for the minibatch.\n",
        "    - reg: (float) regularization strength.\n",
        "\n",
        "    Returns: A tuple containing:\n",
        "    - loss as a single float\n",
        "    - gradient with respect to self.W; an array of the same shape as W\n",
        "    \"\"\"\n",
        "    return softmax_loss_vectorized(self.W, X_batch, y_batch, reg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KOKw3bKKJ08f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "c007c12a-5691-4096-dfee-3e1aa97fa8fd"
      },
      "cell_type": "code",
      "source": [
        "# Use the validation set to tune hyperparameters (regularization strength and\n",
        "# learning rate). You should experiment with different ranges for the learning\n",
        "# rates and regularization strengths; if you are careful you should be able to\n",
        "# get a classification accuracy of over 0.35 on the validation set.\n",
        "results = {}\n",
        "best_val = -1\n",
        "best_softmax = None\n",
        "learning_rates = [1e-7, 5e-7]\n",
        "regularization_strengths = [2.5e4, 5e4]\n",
        "\n",
        "################################################################################\n",
        "# TODO:                                                                        #\n",
        "# Use the validation set to set the learning rate and regularization strength. #\n",
        "# This should be identical to the validation that you did for the SVM; save    #\n",
        "# the best trained softmax classifer in best_softmax.                          #\n",
        "################################################################################\n",
        "\n",
        "# Syntax reminder\n",
        "# def train(self, X, y, learning_rate=1e-3, reg=1e-5, num_iters=100,\n",
        "#            batch_size=200, verbose=False):\n",
        "\n",
        "lr_step = (learning_rates[1] - learning_rates[0]) / 4.0\n",
        "reg_step = (regularization_strengths[1] - regularization_strengths[0]) / 4.0\n",
        "for my_lr in np.arange(learning_rates[0], learning_rates[1], lr_step):\n",
        "  for my_reg in np.arange(regularization_strengths[0], regularization_strengths[1], reg_step):\n",
        "    my_softmax = Softmax()\n",
        "    _ = my_softmax.train(X_train, y_train, learning_rate=my_lr, reg=my_reg, num_iters=1000)\n",
        "    y_train_pred = my_softmax.predict(X_train)\n",
        "    y_val_pred = my_softmax.predict(X_val)\n",
        "    train_acc = np.mean(y_train_pred == y_train)\n",
        "    val_acc = np.mean(y_val_pred == y_val)\n",
        "    \n",
        "    key_tup = (my_lr, my_reg)\n",
        "    val_tup = (train_acc, val_acc)\n",
        "    results[key_tup] = val_tup\n",
        "    \n",
        "    if val_acc > best_val:\n",
        "      best_val = val_acc\n",
        "      best_softmax = my_softmax\n",
        "    \n",
        "################################################################################\n",
        "#                              END OF YOUR CODE                                #\n",
        "################################################################################\n",
        "    \n",
        "# Print out results.\n",
        "for lr, reg in sorted(results):\n",
        "    train_accuracy, val_accuracy = results[(lr, reg)]\n",
        "    print('lr %e reg %e train accuracy: %f val accuracy: %f' % (\n",
        "                lr, reg, train_accuracy, val_accuracy))\n",
        "    \n",
        "print('best validation accuracy achieved during cross-validation: %f' % best_val)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lr 1.000000e-07 reg 2.500000e+04 train accuracy: 0.328020 val accuracy: 0.350000\n",
            "lr 1.000000e-07 reg 3.125000e+04 train accuracy: 0.313041 val accuracy: 0.324000\n",
            "lr 1.000000e-07 reg 3.750000e+04 train accuracy: 0.316286 val accuracy: 0.335000\n",
            "lr 1.000000e-07 reg 4.375000e+04 train accuracy: 0.309388 val accuracy: 0.333000\n",
            "lr 2.000000e-07 reg 2.500000e+04 train accuracy: 0.324755 val accuracy: 0.344000\n",
            "lr 2.000000e-07 reg 3.125000e+04 train accuracy: 0.320163 val accuracy: 0.333000\n",
            "lr 2.000000e-07 reg 3.750000e+04 train accuracy: 0.310143 val accuracy: 0.330000\n",
            "lr 2.000000e-07 reg 4.375000e+04 train accuracy: 0.314265 val accuracy: 0.323000\n",
            "lr 3.000000e-07 reg 2.500000e+04 train accuracy: 0.322490 val accuracy: 0.336000\n",
            "lr 3.000000e-07 reg 3.125000e+04 train accuracy: 0.326020 val accuracy: 0.331000\n",
            "lr 3.000000e-07 reg 3.750000e+04 train accuracy: 0.310796 val accuracy: 0.322000\n",
            "lr 3.000000e-07 reg 4.375000e+04 train accuracy: 0.309633 val accuracy: 0.325000\n",
            "lr 4.000000e-07 reg 2.500000e+04 train accuracy: 0.327082 val accuracy: 0.339000\n",
            "lr 4.000000e-07 reg 3.125000e+04 train accuracy: 0.311918 val accuracy: 0.329000\n",
            "lr 4.000000e-07 reg 3.750000e+04 train accuracy: 0.308041 val accuracy: 0.330000\n",
            "lr 4.000000e-07 reg 4.375000e+04 train accuracy: 0.305878 val accuracy: 0.320000\n",
            "best validation accuracy achieved during cross-validation: 0.350000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rY18wElRJ08i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "75d619a0-d07d-4a64-9941-85516fa97989"
      },
      "cell_type": "code",
      "source": [
        "# evaluate on test set\n",
        "# Evaluate the best softmax on test set\n",
        "y_test_pred = best_softmax.predict(X_test)\n",
        "test_accuracy = np.mean(y_test == y_test_pred)\n",
        "print('softmax on raw pixels final test set accuracy: %f' % (test_accuracy, ))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "softmax on raw pixels final test set accuracy: 0.340000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-iwERfXwJ08l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "a6b2292d-d519-4fbd-c37b-ebc6b3282a7d"
      },
      "cell_type": "code",
      "source": [
        "# Visualize the learned weights for each class\n",
        "w = best_softmax.W[:-1,:] # strip out the bias\n",
        "w = w.reshape(32, 32, 3, 10)\n",
        "\n",
        "w_min, w_max = np.min(w), np.max(w)\n",
        "\n",
        "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i + 1)\n",
        "    \n",
        "    # Rescale the weights to be between 0 and 255\n",
        "    wimg = 255.0 * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min)\n",
        "    plt.imshow(wimg.astype('uint8'))\n",
        "    plt.axis('off')\n",
        "    plt.title(classes[i])"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAAEeCAYAAADLtB9JAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nl68gCIIgTJn/BWiGW5Bkg3w7AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fcd53a512b0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "7EFiDVPKejJy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*Many thanks to Stanford CS231n for permission to use their materials!*"
      ]
    }
  ]
}